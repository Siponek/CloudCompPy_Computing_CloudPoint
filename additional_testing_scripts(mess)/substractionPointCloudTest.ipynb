{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main : Libs loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import psutil\n",
    "os.environ[\"_CCTRACE_\"]=\"ON\"\n",
    "import cloudComPy as cc\n",
    "from gendata import getSampleCloud, dataDir\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import laspy\n",
    "import tqdm\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "print(\"Main : Libs loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Load the data (using laspy -> cloudComPy)\n",
    "# TODO optional convert into pandas dataframe (pandas limit to 100mb?)\n",
    "# TODO Test functions:\n",
    "# - getPointCloud\n",
    "# - getSphere\n",
    "# \n",
    "# TODO Slice the data\n",
    "# TODO Subtract the data, need to ease the surface with gaussian fucntion, search the net for examples\n",
    "# TODO Visualize the data\n",
    "\"\"\" Current plan:\n",
    "        - I cannot see what the functions from cloudComPy are doing(No peek definition), there is only documentation on webstite with no exapmles of functions alone.\n",
    "                There are test cases, however they are not commented or documented on how they are achieving the results.\n",
    "                And for now I don't see clear solution there on how to obtain the difference between two point clouds\n",
    "        - I am creating my own point-clouds for the tests, I need to know how to create them (The libary accepts data in very specific way).\n",
    "                I have made tests for reading the data from a file, but neither .las nor .LiData files are supported in a native way\n",
    "                    Solution to that is to use additional libary called \"laspy\" which is a wrapper for las file format.(And then the data is in diffrent format than the normal data from cloudCompPy)\n",
    "                Reason being that I need small sets of data and visualize them to see if the algorythms work.\n",
    "                I want to see how it is visiualized and how it is subtracted on e.g. two point-cloud spheres. (I want to see if the difference is correct)\n",
    "                If it works on small dataset it will also work on larger dataset.\n",
    "                I cannot use the whole dataset with the mountain because it is too big.( No clear indication of the difference will be visible at this point in time.)\n",
    "        - It requires theory/heavy algebra to understand how the algorythms work. Octree, Hausdorff distance, scalar fields etc.\n",
    "                Even if these functions are present in libary the data must be prepared accordingly to use them. Even more so if I will use my own point cloud data.\n",
    "        - Steps:\n",
    "            1 Create a point-cloud spheres with the data\n",
    "            2 Make a mesh/field form cloud-points(?) (The best way would be to calculate the the distance on the point-cloud and then use the distances to create scalar field, it would give the colours to the diffrenece)\n",
    "            3 Use the Hausdorff distance algo to calculate the difference between the two spheres\n",
    "            4 If it returns the point-cloud with the difference, then it is done.\n",
    "            5 Apply to a big dataset\n",
    "        - I might be missing something from the documentation that could do the job much faster, but I am not an expert on point-clouds.\n",
    "        - Any suggestions/remarks are welcome\n",
    "        \n",
    "\"\"\"\n",
    "\"\"\" Plan with Emanuele:\n",
    "        1       Read the point cloud with Laspy\n",
    "        2       Convert the point cloud to a cloudComPy format (A text file with three float numbers per line)\n",
    "        3       Read the file with cloudComPy\n",
    "        4       Create a mesh from the point cloud / repeat for the second point cloud\n",
    "        5       Make a boolean INTERSECTION operation of the two meshes\n",
    "        5.1     Calculate the Hausdorff distance between the two meshes (using cloudComPy) (Maybe use distance function form cloudComPy)\n",
    "        6       Visualize the difference between the two meshes as one mesh\n",
    "        7       Convert the mesh to a verticies only\n",
    "        8       Convert the verticies to a point cloud and save it as a file\n",
    "\n",
    "    Problem:\n",
    "        1       The Hausdorff distance is not working properly. (it might not give the output that we desire)\n",
    "        2       The information to which point-cloud does a point(Verticies) belong to is lost.\n",
    "        2.1     It is possible to compare XYZ of a point from the difference Mesh of two point-clouds to points of the said clouds.\n",
    "        2.2     But it about 70_000 points per cloud right now so that gives a lot of overhead.\n",
    "        2.3     Need to find a solution for \"height\" of the difference mesh.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"CloudCompare Workflow\"\n",
    "\"\"\"\n",
    "The first thing is to align the 2 point clouds in order to measure only true changes (not the noise of the point clouds). There are 2 options to do this.\n",
    "The first one Align two clouds by picking is if your clouds are not georeferenced. The second one is Finely registers etc. (ICP).\n",
    "You will have to crop the both point clouds to keep the only stable part and apply this second option on the cropped clouds.\n",
    "This gives you the transformation matrix you will have to apply on one of the point cloud (depending on which one you have aligned the other).\n",
    "Once the two point clouds are aligned, you only have to calculate the distance between the two in order to have a point cloud of the changes (distances). \n",
    "You can use either one or the other point cloud as a reference, or you can define a new point cloud regularly spaced to store the distances.\n",
    "The pluggin to do this is already included in cloudcompare.\n",
    "It is called m3c2. You only have to export the distance point cloud as a raster at the end (interpolation can be also done within a GIS if you prefer but it is much much faster within cloudcompare)\n",
    "        by choosing m3c2 distance as active layer to export.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths to files (To be rewritten for CLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All paths are good\n"
     ]
    }
   ],
   "source": [
    "path1 = r\"C:\\\\Users\\\\szinp\\\\Desktop\\\\lazorScan_project\\\\testData\\\\cloud_e4d00e9_CutResult_17_7_42.LiData\"\n",
    "path2 = r\"C:\\\\Users\\\\szinp\\\\Desktop\\\\lazorScan_project\\\\testData\\\\cloud_e4d00e9_CutResult_17_14_7.las\"\n",
    "path3 = r\"C:\\\\Users\\\\szinp\\\\Desktop\\\\lazorScan_project\\\\testData\\\\cloud_e4d00e9_CutResult_17_14_7.LiData\"\n",
    "path4 = r\"C:\\\\Users\\\\szinp\\\\Desktop\\\\lazorScan_project\\\\testData\\\\laser_1_2021-06-01-09-54-35_color_CutResult_17_14_7.las\"\n",
    "path5 = r\"C:\\\\Users\\\\szinp\\\\Desktop\\\\lazorScan_project\\\\testData\\\\laser_1_2021-06-01-09-54-35_color_CutResult_17_14_7.LiData\"\n",
    "path6 = r\"C:\\Users\\szinp\\Desktop\\lazorScan_project\\testData\\1.las\"\n",
    "path7 = r\"C:\\Users\\szinp\\Desktop\\lazorScan_project\\testData\\2.las\"\n",
    "resultPath = r\"C:\\Users\\szinp\\Desktop\\CloudComPy39_20220513\\CloudCompPy_Computing-CloudPoint\\myCloud_test1.las\"\n",
    "assert os.path.isfile(path1)\n",
    "assert os.path.isfile(path2)\n",
    "assert os.path.isfile(path3)\n",
    "assert os.path.isfile(path4)\n",
    "assert os.path.isfile(path5)\n",
    "assert os.path.isfile(path6)\n",
    "assert os.path.isfile(path7)\n",
    "# with open(file=path, mode=\"r\") as cloudFile:\n",
    "#     print(\"Main : File opened\")\n",
    "print(\"All paths are good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3217395809 [00:18<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "with tqdm.tqdm(total=Path(resultPath).stat().st_size) as pbar:\n",
    "    with laspy.open(source = resultPath) as cloudFileHeader:\n",
    "        if type(cloudFileHeader) != None:\n",
    "            cloudFile = laspy.read(source=resultPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<LasHeader(1.2, <PointFormat(0, 56 bytes of extra dims)>)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloudFileHeader.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudFileHeader.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* os.environ[\"_CCTRACE_\"]=\"ON\"                                           # only if you want debug traces from C++\n",
    "\n",
    "#* import cloudComPy as cc                                                # import the CloudComPy module\n",
    "\n",
    "#* cloud = cc.loadPointCloud(\"myCloud.xyz\")                               # read a point cloud from a file\n",
    "#* print(\"cloud name: %s\"%cloud.getName())\n",
    "\n",
    "#* res=cc.computeCurvature(cc.CurvatureType.GAUSSIAN_CURV, 0.05, [cloud]) # compute curvature as a scalar field\n",
    "#* nsf = cloud.getNumberOfScalarFields()\n",
    "#* sfCurv=cloud.getScalarField(nsf-1)\n",
    "#* cloud.setCurrentOutScalarField(nsf-1)\n",
    "#* filteredCloud=cc.filterBySFValue(0.01, sfCurv.getMax(), cloud)         # keep only the points above a given curvature\n",
    "\n",
    "#* ok = filteredCloud.exportCoordToSF(False, False, True)                 # Z coordinate as a scalar Field\n",
    "#* nsf = cloud.getNumberOfScalarFields()\n",
    "#* sf1=filteredCloud.getScalarField(nsf-1)\n",
    "#* mean, var = sf1.computeMeanAndVariance()\n",
    "\n",
    "#* # using Numpy...\n",
    "\n",
    "#* coordinates = filteredCloud.toNpArrayCopy()                            # coordinates as a numpy array\n",
    "#* x=coordinates[:,0]                                                     # x column\n",
    "#* y=coordinates[:,1]\n",
    "#* z=coordinates[:,2]\n",
    "\n",
    "#* f=(2*x-y)*(x+3*y)                                                      # elementwise operation on arrays\n",
    "\n",
    "#* asf1=sf1.toNpArray()                                                   # scalar field as a numpy array\n",
    "#* sf1.fromNpArrayCopy(f)                                                 # replace scalar field values by a numpy array\n",
    "\n",
    "#* res=cc.SavePointCloud(filteredCloud,\"myModifiedCloud.bin\")             #save the point cloud to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertLasTxt(pathToFile : str, nameOfFileOutput : str = \"myCloud.txt\") -> list:\n",
    "    \"\"\"convertLasTxt Converts .las file to .txt file for reading with cloudComPy.\n",
    "    Note: it uses tqdm to show the progress of the conversion.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pathToFile : str\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    listCoord_XYZ = np.empty([1,3])\n",
    "    tmpList = []\n",
    "    x:float = 0.0\n",
    "    y:float = 0.0\n",
    "    z:float = 0.0\n",
    "    #! remark - path 2 has a lot of points, so it takes a while to read it (76_568_359 to be exact).\n",
    "    with tqdm.tqdm(total=Path(pathToFile).stat().st_size) as pbar:\n",
    "        with laspy.open(source = pathToFile) as cloudFileHeader:\n",
    "            if type(cloudFileHeader) != None:\n",
    "                cloudFile = laspy.read(source=pathToFile)\n",
    "                try:\n",
    "                    print(\"Cloud loaded\")\n",
    "                    print(f\"cloud name:{cloudFile.header}\")\n",
    "                except:\n",
    "                    print(f\"cloud name:<unknown>\")\n",
    "                    \n",
    "            #? It seems that chunk_iterator helps to read data in batches. In every batch it reads the data and then it moves to the next batch.\n",
    "            #? Points.array is in fact a one point array. if we set chunk_iterator to (1)\n",
    "            #? What is the data inside of the point? It must be x,y,z and something else. It is possible to extract x,y,z from the point. Is it enough data?\n",
    "            for points in cloudFileHeader.chunk_iterator(1):\n",
    "                x,y,z = points.array[0]['X'], points.array[0]['Y'], points.array[0]['Z']\n",
    "                valuesToAppend = np.array([[x,y,z]])\n",
    "                tmpList.append(valuesToAppend)\n",
    "                # listCoord_XYZ = np.concatenate((listCoord_XYZ, valuesToAppend), axis=0)\n",
    "                # np.append(arr = listCoord_XYZ, values= valuesToAppend , axis=0)\n",
    "                pbar.update(n=1)\n",
    "            listCoord_XYZ = np.array(tmpList) \n",
    "            pbar.close()\n",
    "            np.savetxt(nameOfFileOutput, listCoord_XYZ, delimiter=\" \", newline=\"\\n\")\n",
    "            print(f\"convertLasTxt _> File {nameOfFileOutput} saved\")\n",
    "    print(\"convertLasTxt _> Conversion finished\")\n",
    "    return listCoord_XYZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a sphere pointcloud txt for testing\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass radius as an argument\n",
    "# TODO: Make a hemisphere instead of a sphere\n",
    "\n",
    "def create_points_around_atom(number:int, center:list, radius:float, cutTheShape : bool = True) -> list:\n",
    "\n",
    "    # generate the random quantities\n",
    "    phi         = np.random.uniform( 0, 2*np.pi, size=(number,))\n",
    "    theta_cos   = np.random.uniform(-1,       1, size=(number,))\n",
    "    u           = np.random.uniform( 0,       1, size=(number,))\n",
    "\n",
    "    # calculate sin(theta) from cos(theta)\n",
    "    theta_sin   = np.sqrt(1 - theta_cos**2)\n",
    "    r           = radius * np.cbrt(u)\n",
    "\n",
    "    # use list comprehension to generate the coordinate array without a loop\n",
    "    # don't forget to offset by the atom's position (center)\n",
    "    return np.array([\n",
    "        np.array([\n",
    "            center[0] + r[i] * theta_sin[i] * np.cos(phi[i]),\n",
    "            center[1] + r[i] * theta_sin[i] * np.sin(phi[i]),\n",
    "            center[2] + r[i] * theta_cos[i]\n",
    "        ]) for i in range(number)\n",
    "    ])\n",
    "\n",
    "def createSphere(radius:float = 5, number:int=10,  center:list = [0,0,0], cutTheShape : str = \"None\", leftTreshold : float = 1, rightTreshold : float = 1) -> list:\n",
    "    pi = math.pi\n",
    "    sin = math.sin\n",
    "    cos = math.cos\n",
    "    lst = []\n",
    "    for phi in [(pi*i)/(number-1) for i in range(number)]:\n",
    "        M = int(sin(phi)*(number-1))+1\n",
    "        for theta in [(2*pi*i)/M for i in range(M)]:\n",
    "            x = center[0] + radius * sin(phi) * cos(theta)\n",
    "            y = center[1] + radius * sin(phi) * sin(theta)\n",
    "            z = center[2] + radius * cos(phi)\n",
    "            if (cutTheShape == \"left\" and z<=leftTreshold):\n",
    "                continue\n",
    "\n",
    "            elif (cutTheShape == \"right\" and z>=rightTreshold):\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                lst.append((x, y, z))\n",
    "\n",
    "    return np.array(lst)\n",
    "    # return np.array([\n",
    "    #     np.array([\n",
    "    #         center[0] + radius   * sin(phi) * cos(theta),\n",
    "    #         center[1] + radius   * sin(phi) * sin(theta),\n",
    "    #         center[2] + radius   * cos(phi)\n",
    "    #     ]) for i in range(number)\n",
    "    # ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sphereCoords1 = create_points_around_atom(number=10000, center=[0,0,0], radius=5)\n",
    "sphereCoords1 = createSphere(number=100, center=[0,0,0], radius=5, cutTheShape=\"left\", leftTreshold = 1)\n",
    "sphereCoords2 = createSphere(number=100, center=[0,0,7], radius=6, cutTheShape=\"right\", rightTreshold =5)\n",
    "print(sphereCoords1.shape)\n",
    "print(sphereCoords1)\n",
    "print(sphereCoords2.shape)\n",
    "print(sphereCoords2)\n",
    "np.savetxt(\"testSphere_1.txt\", sphereCoords1, delimiter=\" \", newline=\"\\n\")\n",
    "np.savetxt(\"testSphere_2.txt\", sphereCoords2, delimiter=\" \", newline=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the first .LAS file\n",
    "[]: # Language: python\n",
    "[]: # Path: substractionPointCloudTest.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfCloudPointsFirst = convertLasTxt(pathToFile=path6\n",
    ", nameOfFileOutput=\"myCloud_1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using path2 as input (This is .las data file)\n",
    "# cc.initCC()\n",
    "\n",
    "\n",
    "\n",
    "# listCoord_XYZ = np.array([], ndmin = 2)\n",
    "# listCoord_XYZ = np.empty([1,3])\n",
    "# x:float = 0.0\n",
    "# y:float = 0.0\n",
    "# z:float = 0.0\n",
    "# limit = 0\n",
    "# #! remark - path 2 has a lot of points, so it takes a while to read it (76_568_359 to be exact).\n",
    "# with tqdm.tqdm(total=Path(path6).stat().st_size) as pbar:\n",
    "#     with laspy.open(source = path6) as cloudFileHeader:\n",
    "#         if type(cloudFileHeader) != None:\n",
    "#             cloudFile = laspy.read(source=path2)\n",
    "#             try:\n",
    "#                 print(\"Cloud loaded\")\n",
    "#                 print(f\"cloud name:{cloudFile.header}\")\n",
    "#             except:\n",
    "#                 print(f\"cloud name:<unknown>\")\n",
    "#         # limit = 0\n",
    "#         #? It seems that chunk_iterator helps to read data in batches. In every batch it reads the data and then it moves to the next batch.\n",
    "#         #? Points.array is in fact a one point array. if we set chunk_iterator is set to (1)\n",
    "#         #? What is the data inside of the point? It must be x,y,z and something else. It is possible to extract x,y,z from the point. Is it enough data?\n",
    "\n",
    "#         for points in cloudFileHeader.chunk_iterator(1):\n",
    "#             # print(\"type(points)\\n\", type(points))\n",
    "#             # print(\"points _>\\n\", points)\n",
    "#             # print(\"points array _>\\n\", points.array)\n",
    "#             # print(\"type(points.array[0]) _>\\n\", type(points.array[0]))\n",
    "#             # print(\"points.array[0] _>\\n\", points.array[0])\n",
    "#             # print(\"points.array[0]['X'] _>\\n\", points.array[0]['X'])\n",
    "\n",
    "#             # print(\"points.dtype\\n\", points.dtype)\n",
    "#             # print(\"points.dtype.names\\n\", points.dtype.names)\n",
    "#             x,y,z = points.array[0]['X'], points.array[0]['Y'], points.array[0]['Z']\n",
    "#             valuesToAppend = np.array([[x,y,z]])\n",
    "#             # print(\"(valuesToAppend).shape\",(valuesToAppend).shape)\n",
    "#             # print( \"listCoord_XYZ.shape\", listCoord_XYZ.shape)\n",
    "\n",
    "#             listCoord_XYZ = np.append(arr = listCoord_XYZ, values= valuesToAppend , axis=0)\n",
    "#             # pbar.update(cloudFileHeader.tell() - pbar.n)\n",
    "#             pbar.update(n=1)\n",
    "\n",
    "#             # if limit == 10:\n",
    "#             #     break\n",
    "#             # limit += 1\n",
    "#         pbar.close()\n",
    "#         print(\"listCoord_XYZ\\n\", listCoord_XYZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the first result in a .txt file for compatibility with CloudComPy\n",
    "[]: # Language: python\n",
    "[]: # Path: substractionPointCloudTest.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the second .LAS file \n",
    "[]: # Language: python\n",
    "[]: # Path: substractionPointCloudTest.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfCloudPointsSecond = convertLasTxt(pathToFile=path7\n",
    ", nameOfFileOutput=\"myCloud_2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listCoord_XYZ = np.empty([1,3])\n",
    "# x:float = 0.0\n",
    "# y:float = 0.0\n",
    "# z:float = 0.0\n",
    "# with laspy.open(source = path7) as cloudFileHeader:\n",
    "#     if type(cloudFileHeader) != None:\n",
    "#         cloudFile = laspy.read(source=path4)\n",
    "#         try:\n",
    "#             print(\"Cloud loaded\")\n",
    "#             print(f\"cloud name:{cloudFile.header}\")\n",
    "#         except:\n",
    "#             print(f\"cloud name:<unknown>\")\n",
    "#     # limit = 0\n",
    "#     #? It seems that chunk_iterator helps to read data in batches. In every batch it reads the data and then it moves to the next batch.\n",
    "#     #? Points.array is in fact a one point array. if we set chunk_iterator is set to (1)\n",
    "#     #? What is the data inside of the point? It must be x,y,z and something else. It is possible to extract x,y,z from the point. Is it enough data?\n",
    "#     for points in cloudFileHeader.chunk_iterator(1):\n",
    "#         # print(\"type(points)\\n\", type(points))\n",
    "#         # print(\"points _>\\n\", points)\n",
    "#         # print(\"points array _>\\n\", points.array)\n",
    "#         # print(\"type(points.array[0]) _>\\n\", type(points.array[0]))\n",
    "#         # print(\"points.array[0] _>\\n\", points.array[0])\n",
    "#         # print(\"points.array[0]['X'] _>\\n\", points.array[0]['X'])\n",
    "\n",
    "#         # print(\"points.dtype\\n\", points.dtype)\n",
    "#         # print(\"points.dtype.names\\n\", points.dtype.names)\n",
    "#         x,y,z = points.array[0]['X'], points.array[0]['Y'], points.array[0]['Z']\n",
    "#         valuesToAppend = np.array([[x,y,z]])\n",
    "#         # print(\"(valuesToAppend).shape\",(valuesToAppend).shape)\n",
    "#         # print( \"listCoord_XYZ.shape\", listCoord_XYZ.shape)\n",
    "\n",
    "#         listCoord_XYZ = np.append(arr = listCoord_XYZ, values= valuesToAppend , axis=0)\n",
    "        \n",
    "\n",
    "#         # if limit == 10:\n",
    "#         #     break\n",
    "#         # limit += 1\n",
    "#     print(\"listCoord_XYZ\\n\", listCoord_XYZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the second result in a .txt file for compatibility with CloudComPy\n",
    "[]: # Language: python\n",
    "[]: # Path: substractionPointCloudTest.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"listCoord_XYZ_2.txt\", listCoord_XYZ, delimiter=\" \", newline=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: Make a progress bar for computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('CloudComPy39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6edfd18c23f1977573ae167478fba97ce460a232ec94f55e6f77f6fa0ebec54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
